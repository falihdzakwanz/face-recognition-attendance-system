# ğŸ“ Penjelasan Arsitektur Model Face Recognition

## Untuk Presentasi

---

## ğŸ“‹ Overview Sistem

Sistem ini menggunakan **2 arsitektur Deep Learning**:

1. **CNN (FaceNet + ArcFace)** - Model utama dengan akurasi tinggi
2. **Transformer (DeiT)** - Model alternatif dengan arsitektur modern

---

## ğŸ§  Arsitektur 1: CNN (FaceNet + ArcFace)

### Diagram Alur

```
Input Image (224Ã—224Ã—3)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Face Detection (MTCNN) â”‚
â”‚  - Detect face location â”‚
â”‚  - Align & crop face    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   InceptionResNetV1 Backbone       â”‚
â”‚   (Pretrained on VGGFace2)         â”‚
â”‚   - 380 layer groups               â”‚
â”‚   - Transfer Learning              â”‚
â”‚   - Freeze 360 layers              â”‚
â”‚   - Fine-tune 20 last layers       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Global Average Pooling â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fully Connected Layer          â”‚
â”‚  512 â†’ 128 dimensions           â”‚
â”‚  + Dropout (0.5)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  L2 Normalization       â”‚
â”‚  (Unit hypersphere)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ArcFace Loss Layer         â”‚
â”‚  - Angular Margin: 0.5          â”‚
â”‚  - Scale Factor: 30.0           â”‚
â”‚  - Enhance feature separation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Output: 70 classes
    (Predicted Student)
```

---

### Komponen Detail

#### 1. **Preprocessing (MTCNN)**

- **Multi-task Cascaded CNN** untuk deteksi wajah
- 3 stage cascade: P-Net â†’ R-Net â†’ O-Net
- Output: Face bounding box + 5 facial landmarks
- Alignment: Rotate & crop face berdasarkan eye positions

**Mengapa MTCNN?**

- âœ… Akurat untuk berbagai pose & lighting
- âœ… Detect + align sekaligus
- âœ… Real-time performance

---

#### 2. **Backbone: InceptionResNetV1**

**Struktur:**

```
Inception Modules (Parallel Convolutions)
â”œâ”€â”€ 1Ã—1 Conv (dimensionality reduction)
â”œâ”€â”€ 1Ã—1 â†’ 3Ã—3 Conv (spatial features)
â”œâ”€â”€ 1Ã—1 â†’ 5Ã—5 Conv (larger spatial context)
â””â”€â”€ 3Ã—3 MaxPool â†’ 1Ã—1 Conv (pooling branch)
```

**Keunggulan:**

- Multi-scale feature extraction (1Ã—1, 3Ã—3, 5Ã—5)
- Efficient computation dengan 1Ã—1 conv
- Residual connections untuk gradient flow

**Transfer Learning:**

- Pretrained pada VGGFace2 (3.3M images, 9K identities)
- Fine-tuning: freeze 360/380 layers, train 20 layers terakhir
- Hasil: 27.9M total params, hanya 7M trainable (25%)

---

#### 3. **Embedding Layer**

**128-dimensional Face Embeddings**

```python
Features (512-dim) â†’ FC(512â†’128) + Dropout â†’ L2 Norm â†’ Embeddings
```

**Karakteristik:**

- Compact representation (128-dim)
- Unit hypersphere (||embedding|| = 1)
- Semantic meaning: similar faces â†’ similar vectors
- Cosine similarity untuk matching

---

#### 4. **ArcFace Loss**

**Formula:**

```
L = -log( exp(sÂ·cos(Î¸_yi + m)) / (exp(sÂ·cos(Î¸_yi + m)) + Î£ exp(sÂ·cos(Î¸_j))) )
```

Dimana:

- `s = 30.0` (scale factor)
- `m = 0.5` (angular margin)
- `Î¸_yi` = angle between embedding & correct class weight

**Visualisasi Konsep:**

```
Traditional Softmax:          ArcFace:
   Class A                      Class A
      â†‘                            â†‘
      |                            |  (margin m added)
  ----*---- (decision)         ----*---â”
      |                            |   |margin
      â†“                            â†“   â†“
   Class B                      Class B

   â†’ Easier decision           â†’ Harder training = better features
```

**Mengapa ArcFace?**

- âœ… **Intra-class compactness**: Wajah yang sama jadi lebih dekat
- âœ… **Inter-class separation**: Wajah berbeda lebih terpisah
- âœ… **Angular margin**: Decision boundary lebih ketat
- âœ… Hasil: 99.4% validation accuracy!

---

### Training Strategy

```
1. Load pretrained InceptionResNetV1 (VGGFace2)
2. Freeze backbone layers (360/380)
3. Initialize ArcFace layer randomly
4. Train dengan:
   - Optimizer: Adam (lr=0.0001)
   - Batch size: 32
   - Mixed Precision (AMP) untuk speed
   - Early stopping (patience=10)
   - Learning rate scheduler (patience=5, factor=0.5)
5. Data augmentation on-the-fly (20+ transforms)
```

**Hasil Training:**

- Train Loss: 1.24 (dengan margin â†’ harder)
- Val Accuracy: **99.4%**
- Val F1-Score: **99.4%**
- Training time: ~40 menit (GPU)

---

## ğŸ¤– Arsitektur 2: Transformer (DeiT)

### Diagram Alur

```
Input Image (224Ã—224Ã—3)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Patch Embedding             â”‚
â”‚   - Split: 14Ã—14 patches      â”‚
â”‚   - Patch size: 16Ã—16         â”‚
â”‚   - Flatten: 196 patches      â”‚
â”‚   - Linear projection: 384-dimâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Position Embedding          â”‚
â”‚   (Learnable 1D positional)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Transformer Encoder (12 layers)   â”‚
â”‚                                      â”‚
â”‚   For each layer:                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ Multi-Head Self-Attention  â”‚     â”‚
â”‚   â”‚ - Heads: 6                 â”‚     â”‚
â”‚   â”‚ - Dim per head: 64         â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚            â†“                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ Layer Normalization        â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚            â†“                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ Feed-Forward Network       â”‚     â”‚
â”‚   â”‚ - MLP: 384 â†’ 1536 â†’ 384   â”‚     â”‚
â”‚   â”‚ - GELU activation          â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚            â†“                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ Layer Normalization        â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Classification Head         â”‚
â”‚   - Take [CLS] token          â”‚
â”‚   - Linear: 384 â†’ 70          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Output: 70 classes
```

---

### Komponen Detail

#### 1. **Patch Embedding**

**Konsep:**

- Image 224Ã—224 â†’ Grid 14Ã—14 patches (16Ã—16 each)
- Total: 196 patches
- Setiap patch di-flatten & project ke 384-dim

**Analogi:**

> Image = Kalimat, Patches = Kata-kata

```
Original Image:        Patches:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”¬â”€â”¬â”€â”¬â”€â”
â”‚           â”‚   â†’     â”œâ”€â”¼â”€â”¼â”€â”¼â”€â”¤  (14Ã—14 grid)
â”‚   Face    â”‚         â”œâ”€â”¼â”€â”¼â”€â”¼â”€â”¤
â”‚           â”‚         â””â”€â”´â”€â”´â”€â”´â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         Each = 16Ã—16 pixels
```

---

#### 2. **Self-Attention Mechanism**

**Multi-Head Self-Attention (6 heads):**

```
Query, Key, Value dari input
    â†“
Attention(Q,K,V) = Softmax(QÂ·K^T / âˆšd_k) Â· V
    â†“
Concat all heads â†’ Linear projection
```

**Intuisi:**

- Setiap patch "attend" ke patches lain
- Model belajar: "mata", "hidung", "mulut" â†’ face features
- Global context (tidak seperti CNN yang local)

**Keunggulan:**

- Long-range dependencies
- Position-invariant
- Interpretable attention maps

---

#### 3. **DeiT Distillation**

**Data-Efficient Image Transformer:**

```
Teacher Model (CNN)  â†’  Knowledge Distillation  â†’  Student (Transformer)
   â†“                                                      â†“
Hard labels                                         Soft labels
+ Distillation token                                Learn faster
```

**Hasil:**

- Converge lebih cepat dengan dataset kecil
- Pretrained on ImageNet â†’ fine-tune untuk faces

---

## ğŸ“Š Perbandingan Kedua Arsitektur

| Aspek             | CNN (FaceNet+ArcFace)                | Transformer (DeiT)                  |
| ----------------- | ------------------------------------ | ----------------------------------- |
| **Paradigma**     | Convolution (local)                  | Attention (global)                  |
| **Parameters**    | 28M (7M trainable)                   | 22M                                 |
| **Input Size**    | 224Ã—224                              | 224Ã—224                             |
| **Accuracy**      | **99.4%** â­                         | ~75-85%                             |
| **Training Time** | 40 min (GPU)                         | 60 min (GPU)                        |
| **Inference**     | Fast (~50ms)                         | Slower (~100ms)                     |
| **Pretrain**      | VGGFace2 (faces)                     | ImageNet (objects)                  |
| **Strengths**     | âœ… High accuracy<br>âœ… Face-specific | âœ… Global context<br>âœ… Modern arch |
| **Weakness**      | âŒ Local receptive field             | âŒ Need more data<br>âŒ Slower      |

**Kesimpulan:**

- **CNN** lebih cocok untuk face recognition (99.4% acc)
- **Transformer** sebagai baseline pembanding & research

---

## ğŸ”„ Pipeline Inference (Real-time)

```
Webcam/Upload Image
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MTCNN Detection  â”‚ â† Detect face(s)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
   Face aligned
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preprocessing    â”‚ â† Resize 224Ã—224, normalize
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model Inference  â”‚ â† CNN forward pass
â”‚ (FaceNet+ArcFace)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
   128-dim embedding
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cosine Similarityâ”‚ â† Compare with class weights
â”‚ â†’ Softmax        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
   Confidence score (0-1)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Threshold Check  â”‚ â† Default: 55%
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
  If > threshold:  Student Name
  Else:            "Unknown"
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Attendance Log   â”‚ â† Save to CSV (cooldown: 5 min)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Performance:**

- Detection: ~20-30ms (MTCNN)
- Inference: ~30-50ms (CNN)
- **Total: ~50-80ms per frame** (12-20 FPS)

---

## ğŸ¯ Data Augmentation Pipeline

**On-the-fly transformations (20+ types):**

```python
Augmentation Pipeline:
â”œâ”€â”€ Geometric
â”‚   â”œâ”€â”€ Horizontal Flip (50%)
â”‚   â”œâ”€â”€ Rotation (Â±15Â°)
â”‚   â”œâ”€â”€ Shift/Scale/Rotate
â”‚   â””â”€â”€ Elastic Transform
â”œâ”€â”€ Color
â”‚   â”œâ”€â”€ Brightness (0.8-1.2)
â”‚   â”œâ”€â”€ Contrast (0.8-1.2)
â”‚   â”œâ”€â”€ Hue Shift (Â±20)
â”‚   â”œâ”€â”€ RGB Shift
â”‚   â””â”€â”€ Channel Shuffle
â”œâ”€â”€ Noise
â”‚   â”œâ”€â”€ Gaussian Noise
â”‚   â”œâ”€â”€ Gaussian Blur
â”‚   â””â”€â”€ Motion Blur
â”œâ”€â”€ Quality
â”‚   â”œâ”€â”€ JPEG Compression
â”‚   â”œâ”€â”€ Image Compression
â”‚   â””â”€â”€ Downscale
â””â”€â”€ Advanced
    â”œâ”€â”€ CLAHE (histogram equalization)
    â”œâ”€â”€ Grayscale (10%)
    â”œâ”€â”€ Coarse Dropout
    â””â”€â”€ Grid Distortion
```

**Mengapa Heavy Augmentation?**

- Dataset kecil: ~4-5 foto/mahasiswa
- Generalization: robust ke lighting, pose, quality
- Simulate real-world conditions

---

## ğŸ“ˆ Training Results Visualization

### Loss Curves

```
Train Loss (CNN):
4.0 â”
    â”‚ â•²
3.0 â”¤  â•²___
    â”‚      â•²___
2.0 â”¤          â•²___
    â”‚              â•²___
1.0 â”¤                  â•²___________
    â”‚
0.0 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    0    10    20    30    40    50 epochs

Val Accuracy:
100%â”              ___________________
    â”‚         ____/
80% â”¤     ___/
    â”‚   _/
60% â”¤  /
    â”‚ /
40% â”¤/
    â”‚
0%  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    0    10    20    30    40    50 epochs
```

**Observasi:**

- Train loss tinggi (1.2-1.4) karena angular margin
- Val accuracy cepat converge (epoch 10-15)
- Best model: Epoch 43, Val Acc: 99.4%

---

## ğŸ”¬ Ablation Study

**Percobaan yang dilakukan:**

| Config | Input Size | Loss         | Val Acc   | Note                      |
| ------ | ---------- | ------------ | --------- | ------------------------- |
| 1      | 160Ã—160    | ArcFace      | **99.9%** | Best match (trained @160) |
| 2      | 224Ã—224    | ArcFace      | **99.4%** | Final model (retrained)   |
| 3      | 224Ã—224    | CrossEntropy | ~85%      | Tanpa ArcFace (baseline)  |
| 4      | 160Ã—160    | Triplet      | ~90%      | Original FaceNet          |

**Kesimpulan:**

- ArcFace > CrossEntropy (+14% accuracy)
- Input size match training = critical
- Transfer learning essential (VGGFace2 pretrain)

---

## ğŸ’¡ Key Innovations & Contributions

### 1. **Hybrid Architecture**

- CNN untuk accuracy
- Transformer untuk comparison
- Best of both worlds

### 2. **ArcFace Integration**

- State-of-the-art loss function
- Superior feature separation
- 99.4% accuracy pada dataset kecil

### 3. **Robust Preprocessing**

- MTCNN untuk detection
- Heavy augmentation (20+ transforms)
- Handle real-world variations

### 4. **Production-Ready**

- Real-time inference (50-80ms)
- User-friendly Gradio interface
- Automatic attendance logging
- Privacy-focused (cooldown, threshold)

### 5. **Deployment Flexibility**

- Local deployment
- Cloud (Hugging Face Spaces)
- Easy configuration (YAML)

---

## ğŸ“š References & Theory

### Papers Implemented:

1. **FaceNet** (Schroff et al., 2015)

   - Triplet loss for face verification
   - 128-dim embeddings

2. **ArcFace** (Deng et al., 2019)

   - Additive Angular Margin Loss
   - State-of-the-art face recognition

3. **DeiT** (Touvron et al., 2021)

   - Data-efficient Image Transformers
   - Knowledge distillation

4. **MTCNN** (Zhang et al., 2016)
   - Joint face detection & alignment
   - Cascade architecture

---

## ğŸ¯ Conclusion

**Sistem ini berhasil:**

- âœ… 99.4% accuracy (CNN model)
- âœ… Real-time inference (<100ms)
- âœ… 70 mahasiswa supported
- âœ… Production-ready application
- âœ… Privacy-focused design

**Technical Highlights:**

- Transfer learning from VGGFace2
- ArcFace loss untuk enhanced separability
- Heavy augmentation untuk small dataset
- Dual architecture comparison (CNN vs Transformer)

**Impact:**

- Automated attendance system
- Scalable architecture
- Open-source & reproducible

---