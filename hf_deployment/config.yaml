# Face Recognition System Configuration

# Project Settings
project:
  name: "Face Recognition Presensi Mahasiswa"
  version: "1.0.0"
  author: "Deep Learning Project"

# Paths
paths:
  dataset_root: "dataset"
  train_dir: "dataset/Train"
  val_dir: "dataset/Val"
  test_dir: "dataset/Test"
  output_dir: "outputs"
  models_dir: "models"
  logs_dir: "logs"

# Data Preprocessing
preprocessing:
  face_detection:
    method: "mtcnn" # Options: mtcnn, retinaface, haar_cascade
    min_face_size: 20
    confidence_threshold: 0.95

  face_alignment:
    enabled: true
    target_size: [224, 224] # Width x Height for Transformer (DeiT)
    # target_size: [160, 160]  # Alternative for FaceNet

  data_split:
    train_ratio: 0.75
    val_ratio: 0.0
    test_ratio: 0.25
    random_seed: 42
    stratified: true

  augmentation:
    enabled: true
    horizontal_flip: true
    rotation_range: 15 # degrees
    brightness_range: [0.8, 1.2]
    zoom_range: [0.9, 1.1]
    contrast_range: [0.8, 1.2]
    gaussian_noise: 0.01

# CNN Model Configuration
cnn_model:
  name: "facenet" # Options: facenet, arcface, vggface
  architecture: "InceptionResNetV2"
  pretrained: true
  freeze_layers: true # Freeze early layers
  trainable_layers: 20 # Number of layers to fine-tune

  input_size: [224, 224, 3]  # Updated to 224x224 for Transformer compatibility
  embedding_size: 128

  loss_function: "triplet_loss" # Options: triplet_loss, arcface_loss, cross_entropy
  triplet_margin: 0.2

  optimizer:
    name: "adam"
    learning_rate: 0.0001
    weight_decay: 0.0001

  training:
    batch_size: 32
    epochs: 50
    early_stopping_patience: 10
    reduce_lr_patience: 5
    reduce_lr_factor: 0.5

  dropout: 0.5

# Transformer Model Configuration
transformer_model:
  name: "deit" # Options: vit, deit, swin
  architecture: "deit_small_patch16_224" # timm model name
  pretrained: true
  freeze_backbone: true
  trainable_blocks: 2 # Number of transformer blocks to fine-tune

  input_size: [224, 224, 3]
  num_classes: 70 # Number of students

  loss_function: "cross_entropy"
  label_smoothing: 0.1

  optimizer:
    name: "adamw"
    learning_rate: 0.00001
    weight_decay: 0.05

  training:
    batch_size: 16
    epochs: 100  # Increased for better convergence
    early_stopping_patience: 50  # More patient with small dataset
    reduce_lr_patience: 10  # Reduce LR if no improvement
    reduce_lr_factor: 0.5
    mixup_alpha: 0.2
    cutmix_alpha: 1.0

  dropout: 0.6

# Evaluation Metrics
evaluation:
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_score"

  confusion_matrix: true
  classification_report: true
  top_k_accuracy: [1, 5]

  save_predictions: true
  save_misclassified: true

# Desktop Application
desktop_app:
  framework: "gradio" # Options: gradio, pyqt5, tkinter

  camera:
    device_id: 0
    fps: 30
    resolution: [640, 480]

  recognition:
    confidence_threshold: 0.7
    unknown_threshold: 0.5

  attendance:
    log_file: "attendance_log.csv"
    auto_save: true
    duplicate_prevention_minutes: 5 # Prevent duplicate entries within X minutes

  ui:
    theme: "default"
    show_confidence: true
    show_fps: true
    display_size: [1024, 768]

# System
system:
  device: "cuda" # Options: cuda, cpu, mps (for Mac)
  num_workers: 4
  pin_memory: true
  mixed_precision: true # Use AMP for faster training

  seed: 42
  deterministic: true # Reproducible results

  logging:
    level: "INFO" # DEBUG, INFO, WARNING, ERROR
    format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
